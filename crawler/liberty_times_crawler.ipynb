{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe that we can get news of a day with the link format:\n",
    "http://news.ltn.com.tw/list/newspaper/politics/20181231\n",
    "#### We need a list of date string in the date range we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "#建立從七月到十二月每天的日期\n",
    "start_date = \"2018-07-01\"\n",
    "stop_date = \"2018-12-31\"\n",
    "\n",
    "\n",
    "start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "stop = datetime.strptime(stop_date, \"%Y-%m-%d\")\n",
    "\n",
    "dates = list()\n",
    "while start <= stop:\n",
    "    dates.append(start.strftime('%Y%m%d'))\n",
    "    start = start + timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now write a function to parse the HTML response, return the data we want(title, content, ...etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_document(document, date):\n",
    "    \n",
    "    nodes = document.select('ul.list > li')#找到文章內容標籤位置\n",
    "    data = list()\n",
    "\n",
    "    for li in nodes:\n",
    "\n",
    "        # check if is empty element\n",
    "        if li.select_one('a') == None:#如果沒有連結跳過\n",
    "            continue\n",
    "\n",
    "        # get link\n",
    "        li_link = 'http://news.ltn.com.tw/' + li.select_one('a')['href']#找到每篇文章連結\n",
    "\n",
    "        # request for document\n",
    "        li_res = requests.get(li_link)#要文章的html\n",
    "        li_doc = bs(li_res.text, 'lxml')\n",
    "        #將文章個資料存成dictionary存起來\n",
    "        # get date\n",
    "        li_date = datetime.strptime(date, \"%Y%m%d\").strftime('%Y-%m-%d')\n",
    "\n",
    "        #get title\n",
    "        li_title = li.select_one('p').get_text()\n",
    "\n",
    "        #get content\n",
    "        li_content = \"\"\n",
    "        for ele in li_doc.select('div.text > p'):\n",
    "            if not 'appE1121' in ele.get('class', []):\n",
    "                li_content += ele.get_text()\n",
    "\n",
    "        # append new row\n",
    "        data.append({\n",
    "            'date' : li_date,\n",
    "            'title': li_title,\n",
    "            'link' : li_link,\n",
    "            'content' : li_content,\n",
    "            'tags' : []\n",
    "        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crawl over the news on the site, store the data in variable \"all_data\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start crawling : 20180701\n",
      "start crawling : 20180702\n",
      "start crawling : 20180703\n",
      "start crawling : 20180704\n",
      "start crawling : 20180705\n",
      "start crawling : 20180706\n",
      "start crawling : 20180707\n",
      "start crawling : 20180708\n",
      "start crawling : 20180709\n",
      "start crawling : 20180710\n",
      "start crawling : 20180711\n",
      "start crawling : 20180712\n",
      "start crawling : 20180713\n",
      "start crawling : 20180714\n",
      "start crawling : 20180715\n",
      "start crawling : 20180716\n",
      "start crawling : 20180717\n",
      "start crawling : 20180718\n",
      "start crawling : 20180719\n",
      "start crawling : 20180720\n",
      "start crawling : 20180721\n",
      "start crawling : 20180722\n",
      "start crawling : 20180723\n",
      "start crawling : 20180724\n",
      "start crawling : 20180725\n",
      "start crawling : 20180726\n",
      "start crawling : 20180727\n",
      "start crawling : 20180728\n",
      "start crawling : 20180729\n",
      "start crawling : 20180730\n",
      "start crawling : 20180731\n",
      "start crawling : 20180801\n",
      "start crawling : 20180802\n",
      "start crawling : 20180803\n",
      "start crawling : 20180804\n",
      "start crawling : 20180805\n",
      "start crawling : 20180806\n",
      "start crawling : 20180807\n",
      "start crawling : 20180808\n",
      "start crawling : 20180809\n",
      "start crawling : 20180810\n",
      "start crawling : 20180811\n",
      "start crawling : 20180812\n",
      "start crawling : 20180813\n",
      "start crawling : 20180814\n",
      "start crawling : 20180815\n",
      "start crawling : 20180816\n",
      "start crawling : 20180817\n",
      "start crawling : 20180818\n",
      "start crawling : 20180819\n",
      "start crawling : 20180820\n",
      "start crawling : 20180821\n",
      "start crawling : 20180822\n",
      "start crawling : 20180823\n",
      "start crawling : 20180824\n",
      "start crawling : 20180825\n",
      "start crawling : 20180826\n",
      "start crawling : 20180827\n",
      "start crawling : 20180828\n",
      "start crawling : 20180829\n",
      "start crawling : 20180830\n",
      "start crawling : 20180831\n",
      "start crawling : 20180901\n",
      "start crawling : 20180902\n",
      "start crawling : 20180903\n",
      "start crawling : 20180904\n",
      "start crawling : 20180905\n",
      "start crawling : 20180906\n",
      "start crawling : 20180907\n",
      "start crawling : 20180908\n",
      "start crawling : 20180909\n",
      "start crawling : 20180910\n",
      "start crawling : 20180911\n",
      "start crawling : 20180912\n",
      "start crawling : 20180913\n",
      "start crawling : 20180914\n",
      "start crawling : 20180915\n",
      "start crawling : 20180916\n",
      "start crawling : 20180917\n",
      "start crawling : 20180918\n",
      "start crawling : 20180919\n",
      "start crawling : 20180920\n",
      "start crawling : 20180921\n",
      "start crawling : 20180922\n",
      "start crawling : 20180923\n",
      "start crawling : 20180924\n",
      "start crawling : 20180925\n",
      "start crawling : 20180926\n",
      "start crawling : 20180927\n",
      "start crawling : 20180928\n",
      "start crawling : 20180929\n",
      "start crawling : 20180930\n",
      "start crawling : 20181001\n",
      "start crawling : 20181002\n",
      "start crawling : 20181003\n",
      "start crawling : 20181004\n",
      "start crawling : 20181005\n",
      "start crawling : 20181006\n",
      "start crawling : 20181007\n",
      "start crawling : 20181008\n",
      "start crawling : 20181009\n",
      "start crawling : 20181010\n",
      "start crawling : 20181011\n",
      "start crawling : 20181012\n",
      "start crawling : 20181013\n",
      "start crawling : 20181014\n",
      "start crawling : 20181015\n",
      "start crawling : 20181016\n",
      "start crawling : 20181017\n",
      "start crawling : 20181018\n",
      "start crawling : 20181019\n",
      "start crawling : 20181020\n",
      "start crawling : 20181021\n",
      "start crawling : 20181022\n",
      "start crawling : 20181023\n",
      "start crawling : 20181024\n",
      "start crawling : 20181025\n",
      "start crawling : 20181026\n",
      "start crawling : 20181027\n",
      "start crawling : 20181028\n",
      "start crawling : 20181029\n",
      "start crawling : 20181030\n",
      "start crawling : 20181031\n",
      "start crawling : 20181101\n",
      "start crawling : 20181102\n",
      "start crawling : 20181103\n",
      "start crawling : 20181104\n",
      "start crawling : 20181105\n",
      "start crawling : 20181106\n",
      "start crawling : 20181107\n",
      "start crawling : 20181108\n",
      "start crawling : 20181109\n",
      "start crawling : 20181110\n",
      "start crawling : 20181111\n",
      "start crawling : 20181112\n",
      "start crawling : 20181113\n",
      "start crawling : 20181114\n",
      "start crawling : 20181115\n",
      "start crawling : 20181116\n",
      "start crawling : 20181117\n",
      "start crawling : 20181118\n",
      "start crawling : 20181119\n",
      "start crawling : 20181120\n",
      "start crawling : 20181121\n",
      "start crawling : 20181122\n",
      "start crawling : 20181123\n",
      "start crawling : 20181124\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='news.ltn.com.tw', port=80): Max retries exceeded with url: /news/politics/paper/1249132 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10f376780>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x10f376780>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='news.ltn.com.tw', port=80): Max retries exceeded with url: /news/politics/paper/1249132 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10f376780>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-35944b80dc8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://news.ltn.com.tw/list/newspaper/politics/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mall_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0c0b25689366>\u001b[0m in \u001b[0;36mprocess_document\u001b[0;34m(document, date)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# request for document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mli_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mli_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='news.ltn.com.tw', port=80): Max retries exceeded with url: /news/politics/paper/1249132 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10f376780>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "all_data = list()\n",
    "for date in dates:#從七月一號的文章開始爬到十二月底\n",
    "    print('start crawling :', date)\n",
    "    res = requests.get('https://news.ltn.com.tw/list/newspaper/politics/' + date)#要求當天新聞網站的html\n",
    "    doc = bs(res.text, 'lxml')#將html以BeautifulSoup格式包裝\n",
    "    data = process_document(doc, date)#將文章內容抓出\n",
    "    all_data += data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '〔記者李欣芳／台北報導〕政府積極推動新南向政策，其中推動與新南向國家的救災合作已有腹案，行政院資深官員昨透露，政府除一方面推動與新南向目標國的救災訓練合作外，另方面也要促使台灣消防等救災設備與警報器等儀器的輸出，以協助我廠商爭取商機，目前並規畫與東南亞國家等救災訓練的合作，將以消防署南投竹山訓練中心為訓練基地。南投竹山的消防署訓練中心不僅是國內最大專供消防及災害防救使用的訓練基地，其規模也是全亞洲第一大，這個中心除提供消防、國軍、警大警專消防專業訓練外，也是各級政府災害防救演練及民間救難團體各項救難的訓練場所。資深官員表示，竹山訓練中心是全亞洲最大的災防訓練中心，台灣又擁有優秀的消防等救災人員，未來與新南向國家談妥合作後，對方的人員來台，就會在竹山訓練中心受訓，由我方協助訓練新南向國家的救災人員。據悉，行政院經貿談判辦公室衝刺新南向重點工作計畫，基於台灣地震頻仍、消防等緊急救災有豐富經驗，經貿辦主動提出構想，要推動與新南向國家的救災訓練等合作，目前包括東南亞地區在內，已有國家表達願意與台灣合作的興趣與意願。政府捐助預算成立的新南向智庫「台灣亞洲交流基金會」，有意推動人道救援論壇，由台灣與新南向國家共同探討災變的急難救助與防災議題。資深官員評估，政府推動救災訓練合作，對台灣與新南向國家而言，最終是彼此互惠關係，東南亞等國家可因此增進其災防與急難救助的能力，台灣則可輸出消防衣、滅火器、消防栓設備、自動灑水設備等消防設備與火警自動警報器等儀器，對台灣而言也有不少商機。',\n",
       "  'date': '2018-07-01',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1213127',\n",
       "  'tags': [],\n",
       "  'title': '新南向救災合作 推動消防設備輸出'},\n",
       " {'content': '〔記者陳薏云／新北報導〕位於南投竹山的消防署訓練中心於二○一○年一月十九日啟用，是目前亞洲規模最大、世界上第三大專業消防及防救災實體訓練基地。訓練中心最大特色在於有各式各樣搶救防災的模擬場地，如船舶災害、航空災害等場地，之後也將建造纜車模擬救援場地。訓練中心表示，因為台灣各式地形、建築都有，訓練中心的完整性也吸引許多國家前來參訪、交流。消防署表示，訓練中心占地一○九公頃，面積僅次於約二五○公頃的英國消防學院、約一五○公頃的美國德州農工大學消防訓練中心，但因台灣的面積較小，有別於國外訓練中心的個別成立，消防署訓練中心所設置的實體訓練設施項目是全球最齊全的，共有十二個實體訓練場地；四十九處實火燃燒訓練設施。消防署訓練中心的多元性，吸引不少外國消防單位前來參訪，日本、韓國、英國皆派員來台參訪，目前已與英國消防學院、英國考文垂大學、德州德蘭郡消防訓練中心、美國奧克拉荷馬州立大學及希臘消防協會簽署合作備忘錄。訓練中心正配合行政院經貿談判辦公室推動新南向政策，積極開辦國際性班期，協助東南亞國家提升災害搶救能力，並運用美國國家消防訓練協會（IFSTA）各式教材，建構符合NFPA認證之教學模組，奠定台灣訓練優質水平。有鑑於東南亞地區天然災害頻繁，台灣對於各類型天然災害有救災經驗，期許透過新南向政策推廣，擴大提供東南亞國家防救災專業訓練合作機會，進而強化東南亞救災聯防機制。',\n",
       "  'date': '2018-07-01',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1213128',\n",
       "  'tags': [],\n",
       "  'title': '竹山訓練中心 亞洲最大'},\n",
       " {'content': '〔記者蘇永耀、彭琬馨／台北報導〕美國在台協會（ＡＩＴ）內湖新館已於六月落成，正式運作將至九月間，原本落成典禮美方已規劃閣員級官員來台，但因與「川金會」撞期而暫緩，我方期盼九月開幕時美方能有高階官員來台祝賀，見證台美關係邁入新的階段。相關官員透露，美國政府高度重視ＡＩＴ新館，當初為了落成典禮，台美溝通美方來台官員層級，在整體情勢及彰顯雙邊重要關係等多方面考量下，美國已同意指派較不具政治性的閣員級官員來台。據指出，美國當時可能安排的閣員，包括衛生部長阿札爾、小型企業署署長麥馬洪、環保署長普魯特、勞工部長阿科斯達，甚至具華裔背景的運輸部長趙小蘭等，都曾在台美雙方討論名單之列。官員進一步說，當時的規劃是，無論是哪一位部長來台灣，除出席六月的落成典禮外，我方也會就其業務執掌安排一連串活動，讓台美之間就相關議題尋求實質的合作關係。另外，我方才在五月間世界衛生大會遭到中國打壓無法與會，如能邀請美國衛生部長訪台，也更能凸顯美國挺台參與世衛的態度。不過，原先已設定在六月十二日舉行ＡＩＴ內湖新館的落成典禮，在美國川普總統宣布同一天與北韓領導人金正恩於新加坡進行「川金會」，而使原規劃受到暫緩。相關官員表示，美國政府透過管道向我方表明，川普總統不希望有任何其他活動或因素讓「川金會」失焦，來台官員層級必須調整。最後是由美國國務院主管教育文化的助理國務卿羅伊斯代表來台。雖然六月間的規劃受到暫緩，我方官員認為，台美關係正朝增溫方面前進，除ＡＩＴ內湖新館預定於九月正式運作，ＡＩＴ台北辦事處處長梅健華將在今夏卸任，改由資深外交官酈英傑出任，這也是適當的時間點，屆時美方如能安排高階官員來台，也等於是見證邁入新階段的台美關係。ＡＩＴ新館被形容是美國政府在海外所設具「頂級規格」的駐館，ＡＩＴ前處長楊甦棣任內並積極推動能有「陸戰隊之家」，讓台美關係更具象徵性。美國有線電視新聞網（ＣＮＮ）六月廿九日更報導，一名美國官員表示，數週前已接獲國務院提出派駐「美國陸戰隊使館警衛隊」的要求，美國國務院外交安全局和陸戰隊持續就相關部署協調中。不過，ＡＩＴ重申，新館將與信義路舊址的做法一樣，由一群美方人員搭配人數較多的當地聘僱人員，與地方當局合作，負責維安。',\n",
       "  'date': '2018-07-01',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1213129',\n",
       "  'tags': [],\n",
       "  'title': '9月正式開幕 我盼美高階官員來台 見證AIT新館'},\n",
       " {'content': '〔記者呂伊萱／台北報導〕美國總統川普上任後，以非典型領導與強勢多變的談判作風「讓美國再次強大」。旅美中國時評家陳破空受訪時表示，美國夢對撞中國夢，兩強對決格局已成，是台灣的戰略機遇。他呼籲台灣政府把握時機，對外反制中國打壓，和歐美日俄紐澳等所有大國加強關係；對內則鞏固民主，並鐵腕清查中共在台間諜與第五縱隊，禁止反言論自由的五星旗在台灣飄揚。關注國際局勢的陳破空受訪時評析說，美國當年聯中抗蘇、犧牲台灣，「現在格局翻過來」，美國最大的敵人是中國，意圖聯俄抗中， 從上述國際情勢發展可見一斑。而在文金會、川金會之後，朝鮮半島情勢稍緩，陳破空說，美國更能騰出手關注南海及台海問題。陳破空呼籲，台灣「擁有許多機會」，有許多事可以做，台美不論是提升軍事交流、美軍調派台灣、航母進入台海及高層互訪，「都是可能的」，建議台灣抓住此戰略機遇。陳破空強調，台美關係與中朝關係不同，中朝之間存在矛盾、各有所圖，是朝鮮能在中美之間移動的原因，但「中國是想併吞台灣的敵國」，台美間沒有根本矛盾、是能互信合作的盟國，「本來就該親美」。他指出，蔡政府全面執政，謹守「維持現狀」政策，但現狀並非靜態的，尤其當中國透過各種手段改變現狀時，台灣「不能消極、不能被動、不能等待」，必須採取反制措施。對外應該積極與美歐日、印度、紐澳和俄羅斯等所有世界大國加強關係，「多做少說也行」。對內則需要加強資安、防堵滲透、鐵腕清查線民、間諜和第五縱隊，捍衛國家安全。他也主張立法禁止五星旗在台灣飄揚，「五星紅旗是中國人民的苦難和鮮血，對追求民主的中國人來說都很噁心」。陳破空也特別提醒台灣社會，不應分「藍綠白」，重點在於「親共與反共」。他批評台北市長柯文哲對兩岸的態度「模糊、滑頭」，是非不分、價值混亂且個性善變，「是共產黨喜歡的特首人格特質」。',\n",
       "  'date': '2018-07-01',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1213130',\n",
       "  'tags': [],\n",
       "  'title': '陳破空︰美中對決 台應掌握戰略機遇'},\n",
       " {'content': '記者鄒景雯／特稿最近有位被拒絕入境的中國記者，對於無法再回到台灣駐點的遭遇，表達了「有一點點同情台灣當局」的感受；有關「同情」這個關鍵字，包括如何同情、為何同情，同樣非常值得一談，算是極為誠懇的兩岸對話。由於民族性的不同，對於熱情的台灣人來說，向他人表達同情，絕對不會只是「有一點點」，因此肯定要說是「大大的」同情，何以要大大的同情中國當局？因為這些年來，北京政府何止是「連一個記者都嚇成這樣」，基本上是任何風吹草動都可以嚇成幾倍的這樣；因此，不要說未來讓中國害怕的事還多了呢，應該問：究竟還有哪一件事是中國不害怕的？無所不怕的中國當局，首先害怕李明哲，這位台灣人連記者都不是，既沒有筆，也沒有鏡頭，僅僅是個ＮＧＯ成員，他不過是到中國去與中國人談談民主而已，習近平在十九大不是也談「民主」嗎？怎麼李明哲不是被拒絕入境，也不是驅逐出境，而是被就地失蹤、關押入牢，失去人身自由，罪名竟是「顛覆國家政權罪」，一個手無寸鐵的平民，可以令解放軍現役員額世界第一、表面的國防預算已達世界第二的中國被顛覆，這是被嚇到了什麼地步？其次中國人民得獎，中國當局也要直打哆嗦，劉曉波是因獎嫁禍的典型，不但其本人要打入黑牢至死方休，他寫詩的妻子同被株連必須軟禁，甚至維權人士探望劉霞，也要遷怒其妻舅，予以重罪監禁，這等手筆距離抄家滅族又有何異？第三中國當局是連自己的老兵都害怕，靠槍桿子出政權的中國，照顧退伍軍人是起碼道義，讓老兵上街維權已經寡恩失職，後來演變到武警清場不打緊，進一步要調派軍隊流血鎮壓，不惜殘殺袍澤，這個脆弱政權風聲鶴唳至此，是怎一個怕字了得？以上這些都不夠看，如果再逐一盤點達賴喇嘛、維吾爾語、法輪功，甚至臉書、谷哥，中國當局幾乎是無所不怕，被拒入境的葉青林不妨為大家解惑一下：如果連人都不是的，就能讓習政權嚇成這樣，則中華民族的偉大復興未來要如何走下去？套用中國記者的標準，對於習大大，台灣人必須大大的同情。',\n",
       "  'date': '2018-07-01',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1213131',\n",
       "  'tags': [],\n",
       "  'title': '冷眼集》大大同情中國當局'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#將資料存到liberty_times.pkl\n",
    "with open('data/liberty_times.pkl', 'wb') as f:\n",
    "    pickle.dump(all_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn it into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>新南向救災合作 推動消防設備輸出</td>\n",
       "      <td>http://news.ltn.com.tw/news/politics/paper/121...</td>\n",
       "      <td>〔記者李欣芳／台北報導〕政府積極推動新南向政策，其中推動與新南向國家的救災合作已有腹案，行政...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>竹山訓練中心 亞洲最大</td>\n",
       "      <td>http://news.ltn.com.tw/news/politics/paper/121...</td>\n",
       "      <td>〔記者陳薏云／新北報導〕位於南投竹山的消防署訓練中心於二○一○年一月十九日啟用，是目前亞洲規...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>9月正式開幕 我盼美高階官員來台 見證AIT新館</td>\n",
       "      <td>http://news.ltn.com.tw/news/politics/paper/121...</td>\n",
       "      <td>〔記者蘇永耀、彭琬馨／台北報導〕美國在台協會（ＡＩＴ）內湖新館已於六月落成，正式運作將至九月...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>陳破空︰美中對決 台應掌握戰略機遇</td>\n",
       "      <td>http://news.ltn.com.tw/news/politics/paper/121...</td>\n",
       "      <td>〔記者呂伊萱／台北報導〕美國總統川普上任後，以非典型領導與強勢多變的談判作風「讓美國再次強大...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>冷眼集》大大同情中國當局</td>\n",
       "      <td>http://news.ltn.com.tw/news/politics/paper/121...</td>\n",
       "      <td>記者鄒景雯／特稿最近有位被拒絕入境的中國記者，對於無法再回到台灣駐點的遭遇，表達了「有一點點...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                     title  \\\n",
       "0  2018-07-01          新南向救災合作 推動消防設備輸出   \n",
       "1  2018-07-01               竹山訓練中心 亞洲最大   \n",
       "2  2018-07-01  9月正式開幕 我盼美高階官員來台 見證AIT新館   \n",
       "3  2018-07-01         陳破空︰美中對決 台應掌握戰略機遇   \n",
       "4  2018-07-01              冷眼集》大大同情中國當局   \n",
       "\n",
       "                                                link  \\\n",
       "0  http://news.ltn.com.tw/news/politics/paper/121...   \n",
       "1  http://news.ltn.com.tw/news/politics/paper/121...   \n",
       "2  http://news.ltn.com.tw/news/politics/paper/121...   \n",
       "3  http://news.ltn.com.tw/news/politics/paper/121...   \n",
       "4  http://news.ltn.com.tw/news/politics/paper/121...   \n",
       "\n",
       "                                             content tags  \n",
       "0  〔記者李欣芳／台北報導〕政府積極推動新南向政策，其中推動與新南向國家的救災合作已有腹案，行政...   []  \n",
       "1  〔記者陳薏云／新北報導〕位於南投竹山的消防署訓練中心於二○一○年一月十九日啟用，是目前亞洲規...   []  \n",
       "2  〔記者蘇永耀、彭琬馨／台北報導〕美國在台協會（ＡＩＴ）內湖新館已於六月落成，正式運作將至九月...   []  \n",
       "3  〔記者呂伊萱／台北報導〕美國總統川普上任後，以非典型領導與強勢多變的談判作風「讓美國再次強大...   []  \n",
       "4  記者鄒景雯／特稿最近有位被拒絕入境的中國記者，對於無法再回到台灣駐點的遭遇，表達了「有一點點...   []  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(all_data)[['date', 'title', 'link', 'content', 'tags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
